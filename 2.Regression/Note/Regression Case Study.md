# Regression

## 回归任务示例

**股票预测**：输入过去的股票信息，给出某股票的未来价格；

**无人车**：输入路况，给出驾驶路线；

**推荐系统**：给出使用者A与商品B，给出购买可能性。

## 一个实例：预测Pokemon的战斗力（CP值）

通过将Pokemon的体重等参数作线性变换，得到一个预测值y，表示为其战斗力。

***Step1: Model***

从函数集合中寻找一种$y=b+w \cdot x_{cp}$。此处，使用到的函数是一种线性模型：
$$
y = b + \sum w_i x_i
$$
其中，$x_i$是输入向量的一个维度特征，$w_i$称为权重weight，$b$称为偏置bias。

***Step2: Goodness of Function***

搜集10只pokemon的数据$(x^i, \hat{y}^i)$，进行训练。此时通过设计一个函数，令其输入一个函数，输出其好坏，如：
$$
L(f) = L(w, b) = \sum_{n=1}^{10}(\hat{y}^n - (b + w \cdot x_{cp}^n))^2
$$
函数中$\hat{y}$表示真实值，因此该损失函数含义为估计误差与真实值的平方损失。

***Step 3: Best Function***

从定义好的函数中挑选一个效果最好的，即确定其参数。
$$
\begin{align*}
f^* &= arg\min_f L(f)
\\
w^*, b^* &= arg\min_{w, b} L(w, b)
\end{align*}
$$
***Gradient Descent***

当函数可微分时，通过梯度下降的方式寻找损失函数最小的参数。

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-19 16.23.08.png" alt="截屏2020-08-19 16.23.08" style="zoom:33%;" />

想象函数图像如山谷，在寻找的过程中，设定初始值，得到当前的梯度，观察梯度的方向，向其相反方向移动取值。例如梯度为负数，则有$w^1 = w^0 - \eta \frac{dL}{dw}|_{w=w^0}$。通过相反方向移动，令损失函数的值减小，从而达到我们的优化目的。此处的$\eta$是学习率。通过不断迭代，找到最终值。

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-19 16.22.49.png" alt="截屏2020-08-19 16.22.49" style="zoom:33%;" />

注意，当参数变多的时候，计算梯度交替但独立，即在初值点得到不同参数的微分，对于所有参数使用当前的微分值更新，再计算所有更新后参数的新微分。

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-19 16.28.54.png" alt="截屏2020-08-19 16.28.54" style="zoom:20%;" />

在以上的设定中，如果出现存在Local minima的函数，则优化过程与初值选取都有可能让搜寻陷入困境，然而，**线性回归不存在Local minima**。

### How's the results?-Generalization

虽然训练的过程关心预测误差，但是实际上真正应该关心的是模型的泛化能力，即在测试数据上的表现。

***选择一个复杂的模型***

若考虑$y=b+w_1 \cdot x_{cp} + w_2 \cdot x_{cp}^2$...直至含有五次方项，随着每一次更新模型，在次数较小的时候，对测试数据的误差有可能变小。因此时高次模型实际上包含低次模型的所有函数（将高次项系数设为0即可），故寻找到一个使得训练数据误差最小的函数并非难事。然而，此时加入测试数据后，误差出现了巨大变化：

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-19 16.56.49.png" alt="截屏2020-08-19 16.56.49" style="zoom:13%;" />

当模型复杂过头，就出现了过拟合Overfitting。

***一个启示***

在训练集上的误差下降并不说明什么，我们需要考虑测试数据的效果。

### 另一种思路

***1.分类设计***

也许模型对于不同种类的Pokemon应该区别对待？

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-19 17.10.22.png" alt="截屏2020-08-19 17.10.22" style="zoom:13%;" />

通过设计不同的激活权重，从而在遇到不同的Pokemon时触发不同的权重计算，注意此时仍然是一种线性模型。

***2.正则化***

为了避免模型过于复杂，可以加入正则化项$\lambda\sum(w_i)^2$。此时，损失函数受到该约束，因此会避免模型权重过大。此时，对数值做一个轻微扰动，因权重被限制，预测值$y = b + \sum w_i (x_i+\triangle x_i)$的变化也较小，即函数的图像更加平滑。

设置正则参数可以平衡预测误差和权重本身的比例。正则参数较小，则关注预测误差本身，反之关注权重的取值。当函数较平滑时，对噪声是不敏感的，此时的模型泛化能力更出色，然而过于平滑也会令预测值较差。

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-19 17.24.41.png" alt="截屏2020-08-19 17.24.41" style="zoom:13%;" />

## 误差来自哪儿？

### 偏置与方差

对于均值为$\mu$，方差为$\sigma^2$的N个数据，其均值的期望为$\mu$，但方差的期望实际为$\frac{N-1}{N}\sigma^2$，所以采样N个点时，均值无偏，方差有偏，当然随着N的数量加大，方差会越来越接近真实值。

#### 打靶的例子

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-20 10.40.53.png" alt="截屏2020-08-20 10.40.53" style="zoom:40%;" />

考虑四种情况，是高低偏置与高低方差的组合结果，呈现为上图的四个打靶。可以看到，偏置表示的是整体数据的均值与靶心$\hat{f}$的偏离程度，而方差则是数据的离散程度。因此很显然，低偏置且低方差数据是我们所追求的。

若采样多组数据，对每一组数据拟合一个模型，表现又如何？

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-20 10.45.33.png" alt="截屏2020-08-20 10.45.33" style="zoom:33%;" />

可以看到，简单的模型在面对繁多的采样数据时，变化的程度小得多，而复杂的模型则有可能覆盖较大的候选函数空间。极端情况如一个常函数，无论数据如何采样，它不会变化。因此，复杂的模型拥有较大的方差。

方差衡量数据的变化程度，偏置则关心数据的均值落点。将多组采样形成的不同函数画出，并求均值（蓝线），与真实函数（黑线）对比，得到如下图：

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-20 10.48.01.png" alt="截屏2020-08-20 10.48.01" style="zoom:33%;" />

令人惊奇的是，随着模型复杂，平均后的函数均值更偏向于真实值。可以认为，这是由于简单的模型未包含我们所要的目标函数所造成的当模型越复杂，简单模型为其子集，因此它的函数空间更广，包含有目标函数的可能性越大，则经过较多采样后，偏置可以趋近于真实值了。

因此，一个模型受到的误差来自偏置与方差，这二者都与模型复杂程度相关。若运气好，得到一个已经覆盖目标函数的简单模型，则它方差也较小，从而误差会小许多；否则就需要增加模型的复杂度，以更好地拟合目标数据，寻找到哪个最好的函数，同时，注意提防模型复杂性增加造成的方差加大。

<img src="/Users/LightningX/Learning/ML2020/2.Regression/Note/截屏2020-08-20 10.52.24.png" alt="截屏2020-08-20 10.52.24" style="zoom:33%;" />

#### 如何调节模型

##### 调节偏置

当模型无法拟合训练数据的时候，偏置必然较大，这是一种欠拟合；当模型在训练数据表现极好，测试数据误差大，就有可能有较大的方差，此为过拟合。

对于偏置较大的情况，考虑加入更多的特征输入，或使用更复杂的模型。

##### 调节方差

数据较少时，模型容易不稳定，考虑加大数据用量，可对模型有更大的约束；或使用正则化方法，强迫模型忽视分布较散数据的影响。

